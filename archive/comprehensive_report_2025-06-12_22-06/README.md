# Comprehensive Derivative Approximation Benchmark Report

Generated on: 2025-06-12 22:07:14

## Executive Summary

This comprehensive report analyzes the performance of **3 approximation methods** across **4 derivative orders**, **5 noise levels**, and **3 data sizes** using the Lotka-Volterra periodic ODE system.

**ğŸš¨ CRITICAL FINDING**: Two methods (AAA and LOESS) show **catastrophic failure** for higher-order derivatives, with RMSE values reaching millions while true derivative values are only hundreds.

### ğŸ¯ Key Findings

#### ğŸ† Best Methods by Derivative Order

| Derivative Order | Best Method (Mean) | RMSE | Best Method (Median) | RMSE |
|------------------|-------------------|------|---------------------|------|
| 0 | AAA | 3.46e-02 | AAA | 1.19e-02 |
| 1 | GPR | 1.77e+00 | GPR | 5.51e-01 |
| 2 | GPR | 7.45e+01 | GPR | 6.20e+00 |
| 3 | GPR | 5.12e+01 | GPR | 4.44e+01 |

#### ğŸ“Š Study Parameters
- **Methods Tested**: AAA, GPR, LOESS
- **Noise Levels**: 1.0e-04, 1.0e-03, 5.0e-03, 1.0e-02, 5.0e-02
- **Data Sizes**: 21, 51, 101 points
- **Derivative Orders**: 0, 1, 2, 3
- **Total Unique Combinations**: 360
- **Total Individual Evaluations**: 20,760

#### ğŸ”¥ Method Performance & Failure Analysis

**Overall Rankings** (by mean RMSE across all conditions):
1. **GPR**: 3.19e+01 (Â±6.25e+01)
2. **AAA**: 6.73e+06 (Â±6.05e+07)
3. **LOESS**: 1.10e+07 (Â±1.10e+08)


**Method Reliability** (% of runs with reasonable RMSE < 1000):
- **AAA**: 84.2% reliable
- **GPR**: 100.0% reliable
- **LOESS**: 77.5% reliable


#### ğŸ” Error Magnitude Investigation

**The RMSE values represent ABSOLUTE errors, not relative errors.**

For context on the extreme RMSE values:
- **True derivative values** typically range from -300 to +400
- **GPR predictions** stay within reasonable bounds (max errors ~37% for 3rd derivatives)
- **AAA/LOESS predictions** completely diverge, reaching Â±17 million!

**Relative Error Analysis**:
- **GPR**: Maintains <40% relative error even for 3rd derivatives
- **AAA**: Relative errors reach 3,000% for higher derivatives  
- **LOESS**: Relative errors exceed 30,000% for 3rd derivatives

#### ğŸ¯ Practical Recommendations

1. **For Function Values (Order 0)**: All methods perform reasonably well
2. **For 1st Derivatives**: GPR or AAA are both acceptable
3. **For 2nd+ Derivatives**: **Use GPR exclusively** - other methods fail catastrophically
4. **For Noisy Data**: GPR shows superior robustness across all noise levels
5. **For Large Datasets**: GPR scales well computationally

#### ğŸ“ˆ Performance Trends

- **Performance Degradation**: All methods worsen with derivative order, but GPR degrades gracefully
- **Noise Sensitivity**: GPR maintains stability; AAA/LOESS become unstable
- **Data Efficiency**: More data points consistently improve GPR performance
- **Computational Cost**: GPR has reasonable computational overhead for its accuracy

## Detailed Analysis

### Visualizations Generated

1. **Error Magnitude Analysis** (`error_magnitude_analysis.png`)
   - True value ranges vs predicted values by method
   - Demonstrates the catastrophic failure of AAA/LOESS

2. **Enhanced Heatmaps** (`enhanced_heatmaps.png`)
   - Mean RMSE, Median RMSE, and Coefficient of Variation
   - Shows method stability across conditions

3. **Multi-Factor Analysis** (`multifactor_analysis.png`)
   - RMSE vs noise level by derivative order
   - Point size represents data size effects

4. **Noise Sensitivity** (`noise_sensitivity.png`)
   - Method robustness to different noise levels
   - GPR maintains stability while others fail

5. **Data Size Analysis** (`data_size_analysis.png`)
   - Performance scaling with number of data points
   - Shows convergence behavior

6. **Performance-Time Analysis** (`performance_time_analysis.png`)
   - Computational efficiency trade-offs
   - Method scaling characteristics

7. **Stability Analysis** (`stability_analysis.png`)
   - Method consistency across conditions
   - Failure rate analysis

### Data Quality Assessment

- **Total Evaluations**: 20,760 individual measurements
- **Study Coverage**: 3 methods Ã— 4 derivatives Ã— 5 noise levels Ã— 3 data sizes
- **Robustness**: Multiple observables tested for each condition

### Missing Methods

**Note**: This analysis covers 3 of the 5 available methods. Missing methods:
- AAA_lowpres (lower precision AAA)
- BSpline5 (B-spline approximation)

These were not included due to technical issues but could provide additional insights.

## Conclusions

### ğŸ¯ Primary Conclusion
**Gaussian Process Regression (GPR) is the clear winner** for derivative approximation with noisy ODE data, especially for higher-order derivatives where other methods fail catastrophically.

### ğŸ”¬ Scientific Impact
This study provides definitive evidence for method selection in derivative approximation tasks:
- **GPR**: Reliable across all conditions
- **AAA**: Acceptable for low-order derivatives only
- **LOESS**: Not recommended for derivative computation

### ğŸ› ï¸ Implementation Guidance
For practitioners working with noisy ODE data:
1. **Default choice**: Use GPR for all derivative approximation tasks
2. **Special cases**: AAA may be considered for function values only
3. **Avoid**: LOESS for any derivative computation beyond 1st order

---

## Files Generated

### Visualizations
- `figures/error_magnitude_analysis.png`: Error scale investigation
- `figures/enhanced_heatmaps.png`: Method comparison matrices  
- `figures/multifactor_analysis.png`: Multi-dimensional performance analysis
- `figures/noise_sensitivity.png`: Robustness to noise
- `figures/data_size_analysis.png`: Scaling with data quantity
- `figures/performance_time_analysis.png`: Computational efficiency
- `figures/stability_analysis.png`: Method reliability assessment

### Data Tables
- `best_methods_detailed.csv`: Optimal method per derivative order
- `comprehensive_performance_matrix.csv`: Complete statistical summary
- `method_rankings.csv`: Overall method performance rankings
- `failure_analysis.csv`: Method reliability statistics

### Methodology
- **Benchmark System**: Lotka-Volterra periodic ODE
- **Error Metric**: Root Mean Square Error (RMSE)
- **Evaluation**: Function values and derivatives (orders 0-3)
- **Statistical Approach**: Multiple noise levels, data sizes, and observables

---

*Comprehensive report generated using Python with pandas, matplotlib, and seaborn*
*Analysis based on 20,760 individual benchmark evaluations*
